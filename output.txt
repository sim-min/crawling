스칼라, 벡터에 대해 알아보자
수와 대수학에 대한 밑밥을 깔아놓았으니 드디어 딥러닝이라는 요리에 쓰이는 식재료, 스칼라와 벡터, 매트릭스에 대한 얘기를 하겠다.

좀 거칠게 비유해서 말하자면 딥러닝에 있어서

스칼라 = 가중치
벡터 = 대상 (언어모델에서는 각각의 단어나 문장), 혹은 가중치들의 모음
행렬 = 대상에 대해 가하는 어떤 액션, 혹은 벡터들의 모음
텐서 = 전체 모델

을 나타내는 수단이다.

먼저
 스칼라

 - 이놈의 텐서 랭크는.. 0 이다
 - 축이 없고 그냥 숫자만 하나 달랑 있는 놈이다. 더 이상 단순할 수 없는 대수학적 대상이다

그런데 이름이 왜 스칼라일까?
 - 위키피디아나 나무위키 등을 찾아보면 Scale 을 나타내는게 기본 용도라서 '스케일값' 이 어원인 것 같다. 영어로는 '스케일러' 라고 발음해도 된다고 한다. 스케일은 영어로 '저울'이다. 무거움의 정도 = 스케일 = 스케일러 = 스칼라이다

이전 시간에 숫자의 의미를 설명하면서 숫자는 크기를 나타낼 수도, 순서를 나타낼 수도, 액션을 나타낼 수도 있다고 했다.
우리의 경우 스칼라는 크기를 나타내는데 사용하는 cardinal number 라고 생각하되, 때로는 크기를 변형시키는 액션이라고 생각하는게 더 어울릴 수도 있다.
 - 즉 1 이면 줄이지도 늘리지도 않는 기본 값이라고 생각하자. 0.5 면 50% 로 줄이는 느낌, 2.0 이면 200% 로 2배 불리는 느낌, 0 이면 아무것도 안하는게 아니라 콱 죽여버리는 느낌이다.

예를 들면 
    1girl, solo, (huge_breasts:1.5) 같은 식으로 디퓨전 가중치를 줬다고 하자.

각 단어에 대한 가중치는 1, 1, 1.5 로 구성되어있다고 생각할 수 있겠지. 
      이 경우에는 스칼라가 0 이면 아무것도 안하는게 아니라 그냥 죽여버리는 무언가라는 느낌을 생각하자. 

암튼 스칼라.. 혹은 스케일러... 묵직함을 조절하는 그 무언가라는 느낌을 기억해두자. 그리고 액션으로 사용될 수도 있다고 생각해두자.

액션이란 관점에서 생각할 때에는 ((huge_breasts:1.3):1.4) 라는 프롬프트 태그를 보면 가중치가 몇이 되었다고 생각해야 자연스러울까? 1.3+1.4 = 1.7?  아니면 1.3*1.4 = 1.82? 이 부분은 연습문제로 남겨두겠다.


벡터
  일단 이놈의 텐서 랭크는 1이다. 축이 한개이고, 그 축에 여러개의 숫자가 나열된 형식이다.
  벡터의 어원은 라틴어 vehere 라고 한다. vehere 뜻이 운반하다.. 인데 물리학에서 움직임을 나타내기 위한 값으로 정했다.
  움직이는 방향을 숫자로 나타내려면 2차원 공간이라면 x축, y축 같은 2개의 숫자가 필요하고, 3차원 공간이라면 3개의 숫자가 필요할 것이다. 물리학의 벡터 개념은 수학으로 넘어가서 좌표공간에서의 방향 개념으로 일반화되었는데 이게 또 컴퓨터로 넘어오면서는 그냥 여러 숫자의 다발을 의미하는 것으로 바뀌었다. c 언어에서 std::vector 같은 클래스는 그냥 숫자를 여러개 담을수 있다는 의미일 뿐 수학이나 물리학적인 의미와는 많이 멀어진 개념이 되었다. 그러니 그쪽의 벡터 개념은 생각하지 말자.

그럼 딥러닝에서의 벡터는 어떤 의미를 가질까?

      3가지로 나누어 생각해볼 수 있다

첫번째로는 여러개의 스칼라를 모아놓은 것이다
      아까 예제에서 1girl, solo, (huge_breasts:1.5) 같은 프롬프트의 가중치들은
      (1, 1, 1.5) 라는 스칼라들의 묶음으로 다룰 수 있다.
스칼라를 벡터로 묶어놓으면 나중에 CPU 에서 연산을 하거나 GPU 에서 연산을 할 때 한번에 묶어서 처리할 수 있다. 이걸 벡터화(vectorization) 라고 한다. 보통 CPU 는 레지스터 사이즈가 512 비트씩 되는데, 이거면 32비트짜리 스칼라를 한번에 16개씩 더하거나 곱하거나 할 수 있으니까 멀티쓰레딩 같은 것에 의존하지 않고 연산을 16배 가속할 수 있다.


두번째는 엠베딩같은 값, 딥러닝에서 대상을 표현하는 수단이다. 

엠베딩은 좀 설명이 복잡해지니까 상대적으로 더 쉬운 '색상' 을 소재로 설명하겠다.

컴퓨터 (더 구체적으로는 sRGB 표준) 에서는 색상을 표현하기 위한 방법으로 RGB 표기법을 사용한다. 빛의 삼원색인 R, G, B 의 강도를 각각 0~1 혹은 0~255 중 하나의 숫자로 나타내고, 그 숫자들을 묶으면 3차원 벡터가 된다.

이 벡터들이 존재할 수 있는 범위를 통칭해서 벡터공간, 짧게 '공간' 이라고 표현한다. 벡터는 공간을 이탈할 수 없다
   예를 들어 (-1, 0, 0) 같은 색은 색상 공간에서는 있을 수 없는 벡터이다. 아웃.

sRGB 같은 것은 색을 나타낼 수 있는 공간의 한 종류이며 R,G,B 가 0~1 사이의 값을 가질 수 있는 공간이다. 그런데 색을 RGB 같은 공간에서 나타내면 좀 불편한 점들이 있다.
      예를 들어서 빛을 나타내는 데에는 RGB 의 강도라는 방법 말고, 색상, 채도, 명도 같은 관점 (HSV)으로 나타낼 수도 있다

이런 방법으로 나타내면 좋은 점이 뭘까?
      '어떤 그림을 전체적으로 채도를 10% 정도 줄여서 약간 물빠진 색감을 내고 싶다' 라는 변형을 하고 싶다고 하자.
        대수학적으로 표현하자면 원본 그림의 공간에 있는 각각의 원소 픽셀에 대해 10% 채도를 낮추는변형을 가해서 타겟 공간으로 옮기는 변환 이라고 할 수 있다
      이때 색이 RGB 형식으로 나타나있다면 10% 채도를 낮추는 변형을 간단히 정의하기 어렵겠지만, HSV 공간으로 옮겨져 있다면 간단하게 ,H값과 V 값은 놔두고 S 값만 0.9 를 곱해주는 함수를 통과시키기만 하면 된다
        HSV 공간은 Hue, Saturation, Value 를 의미하며 색상 채도 명도가 각 좌표축을 의미한다 
https://ko.wikipedia.org/wiki/HSV_%EC%83%89_%EA%B3%B5%EA%B0%84

딥러닝을 배우고 싶은건데 자꾸 밑바닥 수학얘기를 하는 것이 납득하기 어려울 수도 있다. 그 부분에 대해서는 따로 하고 싶은 말이 있다.

앞으로도 딥러닝의 개념을 공부하다보면 대수학에 대한 얘기는 계속 나올 수 밖에 없고, 이 기초를 모르면 그냥 무작정 외우거나 받아들이는 수 밖에 없다.

예를 들어서 트랜스포머에 등장하는 쿼리 벡터와 키 벡터는 벡터의 성분끼리 곱해서 그 결과들을 모아서 다시 벡터로 모아야 하는데, 이런식의 벡터 곱셈은 일반적인 기하학에서는 배우지 않는다. 고등학교 기하에서도 벡터의 내적이나 외적을 배우지, 성분들끼리 곱하는 것은 배우지 않는다. 또한 행렬과 행렬을 곱할때도 선형대수학식으로 곱하는 것 말고도 각 멤버들끼리 곱하는 방식 (hadamard product) 들도 있다. 

왜 이런 차이가 생기는걸까? 그것은 벡터의 경우 2가지의 경우가 있다고 했기 때문이다. 
 - 첫번째로는 단순히 벡터가 여러개의 가중치들을 묶어놓은 경우, 
 - 두번째로는 벡터가 임베딩처럼 공간 내의 구체적인 대상을 다루는 경우. 

첫번째의 경우에는 아다마르 곱이 어울릴 것이지만 두번째 경우에는 실제 변환에 해당하는 곱을 하는 것이 어울릴 것이다. 실제 증명이나 계산은 할줄 몰라도 좋지만, 어떤 경우에는 어떤 계산법이 어울릴 것 같다라는 느낌만큼은 알아두면 좋겠다. 

다시 얘기하는 것이지만 이것만은 기억해두기 바란다. 벡터는 단순히 가중치의 모임일 수도 있고, 어떤 존재를 수치화한 것(엠베딩)일 수도 있다. 이런 얘기들은 나중에 등장하는 시점에서 다시 강조할테니 일단은 스칼라나 벡터가 어떤 존재인지에 따라 그것에 대한 연산법도 달라진다라는 점을 기억해두자. 이 부분에서 헷갈리면 내가 딥러닝을 이해하는 주도권을 빼앗기고 그냥 멍하니 따라가게 되어버린다.

이전 글에서 대수학 얘기를 하면서 수를 액션으로 생각하고, 액션과 액션의 조합에 대한 패턴을 연구하는 것이 대수학이라고 설명했었다.

스칼라와 벡터 둘 다 대수학적으로 다루는 대상이긴 하지만, 그렇다고 해서 아무렇게나 액션을 조합할 수 있는 것은 아니다. 논리적으로 말이 되는 경우에 연산이 가능한거고, 그 규칙을 벗어나서 억지로 연산한 결과는 논리적이지 않은 결과가 나올 것이다.

예를 들어서 생각해보자. 2차원 공간이 있다고 하고, 그 위에 위치를 나타내기 위해서 2차원 벡터를 사용하자. 또한 방향을 나타내기 위해서도 2차원 벡터를 사용하자. 

위치를 나타내는데에는 숫자 2개가 필요하고, 방향을 나타내는데에도 숫자 2개가 필요한데, 그 2개의 개념은 서로 같은 개념일까? 하나의 개념이 들어갈 자리에 다른 개념이 들어가도 문제가 없는걸까?

가중치 * 가중치  -> OK. 가중치를 가하는 액션을 2번 수행했다고 생각할 수 있다
가중치 * 방향벡터  -> OK. 그 방향으로 가중치 배수만큼 강화된 강도라고 생각할 수 있다. (속력이 2배)
가중치 * 위치벡터  -> ???  위치가 2배라는 것은 엄밀하게 논리적으로 말이되지 않는다. 위치라는 것은 원점으로부터 방향벡터만큼 이동한 결과라고 생각할 수는 있지만, 그것은 변환의 방법이지 방향과 위치가 같은 개념은 아니다. 
스칼라 + 방향벡터 -> ??? 역시 논리적으로 넌센스이다. 
방향벡터 + 방향벡터 -> OK. 두개의 방향이 합성된 새로운 방향을 만들어진다
방향벡터 * 방향벡터 -> ?? 두개의 방향을 합성하는 것은 이미 덧셈으로 정의했다. 방향을 곱한다는 것은 어떤 의미일까? 두 벡터의 내적을 구하면 스칼라가 나오고, 외적을 구하면 새로운 벡터가 나오긴 하는데 그것은 두 방향의 합성과는 다른 의미가 된다.
방향벡터 * [가중치,가중치] -> 2차원 방향벡터에 대해 각 방향별로 가중치를 곱해주는 것이 의도다라고 하면 각 성분끼리 곱한 것을 다시 벡터로 만드는 것은 가능하다.
위치 + 위치 -> ??? 논리적으로 넌센스이다
위치 - 위치  -> 두 위치간의 방향을 구하는 것은 OK. 대신 이렇게 연산한 결과는 위치가 아니라 방향벡터다.
위치 * 위치  -> ??? 넌센스

수학이 아니라 2d엔진을 만들기 위해서 코딩을 한다고 생각해보자. 방향과 위치 둘다 2개의 number 쌍으로 표현할 수는 있지만, 논리적 오류를 막으려면 두 대상을 연산하는 경우를 제한해야 한다. 

아직 행렬이나 텐서를 다루지 않았기 때문에 스칼라와 벡터가 연산을 하는 경우만 써놨는데, 마찬가지로 텐서간의 연산을 할 때 이게 무슨 논리적 의미를 갖고 하는 연산인지를 모르면 논리적 오류에 빠질 수 밖에 없다. 파이토치 같은 라이브러리는 브로드캐스트라는 편의기능이 있어서 임시로 스칼라를 벡터로 쭉 복사해서 펴준다던가, 벡터를 행렬로 펴준다던가 하는 기능이 있는데, 내가 뭘하는지 알고 쓰면 코딩량을 줄여주는 편리한 기능이지만 그렇지 않으면 독이 될 수도 있기 때문이다.